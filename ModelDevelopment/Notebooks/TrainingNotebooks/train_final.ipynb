{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training Notebook\n",
    " - This notebook is based on the training notebook provided by Hugging Face inside their documentation (https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb#scrollTo=YVx71GdAIrJH).\n",
    "  - Important to note is that testing results may be misleading since all the data is labeled using heuristics and not manually. Proper testing should be done with manually labeled data but since manual labeling was deemed too time-consuming. I tested my models on some edge cases which I deemed important. Also, the app itself is a great way to test the model in the intended environment.\n",
    "\n"
   ],
   "id": "825f13d03af37184"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# pip install datasets evaluate seqeval # for google colab ",
   "id": "577122225d74aa4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import transformers\n",
    "from numpy.f2py.cfuncs import callbacks\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, AdamW, TrainerCallback\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import csv\n",
    "import sys\n",
    "csv.field_size_limit(2**31 - 1)\n",
    "from urllib.parse import urlparse"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T22:34:31.121453Z",
     "start_time": "2024-10-21T22:34:31.116244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_checkpoint = \"roberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "batch_size = 16\n",
    "\n",
    "label_all_tokens = False\n",
    "label_map = {'O': 0, 'B-PRODUCT': 1, 'I-PRODUCT': 2} # bert expects labels to be in the form of integers\n",
    "reverse_label_map = {v: k for k, v in label_map.items()} # we will use this to convert the model's output back to the original labels for metrics"
   ],
   "id": "a917852054efe345",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Parsing Methods\n",
    "- The read_csv_file_grouped_by_base_url method is made specifically for grouping the data based on the url (it was initially dispersed due to having a different goal before deciding otherwise)."
   ],
   "id": "280b5d62e3dac7aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T22:34:32.530751Z",
     "start_time": "2024-10-21T22:34:32.524049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_base_url(url):\n",
    "    try:\n",
    "        parsed_url = urlparse(url) # parse the URL using the library\n",
    "        base_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\"\n",
    "        return base_url\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def read_csv_file_grouped_by_base_url(file_path):\n",
    "    data_by_url = {}\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            # skip the header\n",
    "            if row[0] == \"URL\":\n",
    "                continue\n",
    "\n",
    "            url, tokens_str, labels_str = row\n",
    "            tokens = tokens_str.split(' ')\n",
    "            labels = labels_str.split(' ')\n",
    "\n",
    "            base_url = get_base_url(url)  # get base URL\n",
    "\n",
    "            # group sentences and labels by base URL\n",
    "            if base_url not in data_by_url:\n",
    "                data_by_url[base_url] = {'sentences': [], 'labels': []} \n",
    "\n",
    "            # this also keeps the order of the tokens in respect to the labels\n",
    "            data_by_url[base_url]['sentences'].append(tokens) \n",
    "            data_by_url[base_url]['labels'].append(labels)\n",
    "            \n",
    "\n",
    "    # now we convert labels to integers since that is what the model expects\n",
    "    for base_url, data in data_by_url.items():\n",
    "        for i in range(len(data['labels'])):\n",
    "            data['labels'][i] = [label_map[label] for label in data['labels'][i]]\n",
    "\n",
    "    return data_by_url"
   ],
   "id": "a50d8521eb281cfc",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train / Test Split\n",
    "- Important to note here is that, even though I am using rule-based data for testing also, I am only testing on data that was extracted from base URLs that were not used for training.\n",
    "- The testing performance is directly tied to the quality of the training data.\n",
    "- This ensures to some degree that the F1 score is not misleading.\n",
    "- If anything, if the model is trained well, considering all the noise in the data (both training and test), an F1 of around 0.9 should be considered more than sufficient and should indicate decent model performance."
   ],
   "id": "abb89af76e60ea28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T22:34:34.602904Z",
     "start_time": "2024-10-21T22:34:34.377246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load and group your data by base URL\n",
    "dataset_path = \"../../Data/TrainingDatasets/100000_TL25_TR40_ST80.csv\"\n",
    "data_by_url = read_csv_file_grouped_by_base_url(dataset_path)\n",
    "\n",
    "# get the list of unique base URLs\n",
    "base_urls = list(data_by_url.keys())\n",
    "\n",
    "# perform the train/test split on the base URLs (instead of individual entries)\n",
    "train_urls, test_urls = train_test_split(base_urls, test_size=0.15, random_state=42)\n",
    "\n",
    "# now split the data into train and test sets based on the base URLs\n",
    "train_sentences, train_labels = [], []\n",
    "test_sentences, test_labels = [], []\n",
    "\n",
    "for base_url in train_urls:\n",
    "    train_sentences.extend(data_by_url[base_url]['sentences'])\n",
    "    train_labels.extend(data_by_url[base_url]['labels'])\n",
    "\n",
    "for base_url in test_urls:\n",
    "    test_sentences.extend(data_by_url[base_url]['sentences'])\n",
    "    test_labels.extend(data_by_url[base_url]['labels'])\n",
    "\n",
    "print(f\"Training entries: {len(train_sentences)}, Testing entries: {len(test_sentences)}\")\n"
   ],
   "id": "2200bd0cc0c0f703",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 5051, Testing entries: 949\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tokenization and Alignment\n",
    "- Method to tokenize and align labels in accordance to the requirements of the tokenizer."
   ],
   "id": "459c1fb3e417995a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T22:34:35.986423Z",
     "start_time": "2024-10-21T22:34:35.981374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_and_align_labels(train_sentences, train_labels):\n",
    "    tokenized_inputs = tokenizer(train_sentences, truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    special_token_ids = tokenizer.convert_tokens_to_ids(special_tokens) # we need to have access to the special token ids (for ignoring them in the loss function since they were set not to -100)\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(train_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        input_ids = tokenized_inputs['input_ids'][i]\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx, input_id in zip(word_ids, input_ids):\n",
    "            # special tokens have a word id that is None (except the ones added manually). We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None or input_id in special_token_ids:\n",
    "                label_ids.append(-100)\n",
    "            # if this is the first token of a word, use the corresponding label\n",
    "            elif word_idx != previous_word_idx:\n",
    "                if word_idx < len(label):  # check if the word index is within label range\n",
    "                    label_ids.append(label[word_idx])\n",
    "                else:\n",
    "                    # if the word index is out of range, append -100 (ignore token)\n",
    "                    label_ids.append(-100)\n",
    "            # for the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ],
   "id": "c6973dabaaa86692",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T22:34:40.027933Z",
     "start_time": "2024-10-21T22:34:37.644107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True) # remove the add_prefix_space if you are using a model that doesn't require it\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n",
    "\n",
    "# we add the special tokens\n",
    "special_tokens = ['[URL]', '[TITLE]', '[TEXT]', '<NO_TITLE>', '<NO_URL>']\n",
    "\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})\n",
    "\n",
    "# tokenize and align labels for both training and test datasets\n",
    "train_data = tokenize_and_align_labels(train_sentences, train_labels)\n",
    "test_data = tokenize_and_align_labels(test_sentences, test_labels)\n",
    "\n",
    "# convert the tokenized data to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n"
   ],
   "id": "f6e83b7dd7e348ec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boroz\\Documents\\GitHub\\FurnitureStoresExtraction\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Weighted Trainer Class\n",
    "- This inheritance was created so I can emphasize the importance of the 'B-PRODUCT' label in the loss function since I was getting I-PRODUCT labels without the B-PRODUCT labels at the beginning.\n",
    "- In the statistics, this creates an imbalance between the precision and recall in favour of the latter."
   ],
   "id": "c8fc744f642220f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T22:34:44.404835Z",
     "start_time": "2024-10-21T22:34:44.398987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs[\"labels\"]  # keep labels in the input\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # move class weights to the same device as logits\n",
    "        device = logits.device\n",
    "        class_weights = torch.tensor([0.1, 3.0, 1.0], dtype=torch.float).to(device)\n",
    "\n",
    "        # flatten logits and labels\n",
    "        logits = logits.view(-1, len(label_map))  # (batch_size * sequence_length, num_labels)\n",
    "        labels = labels.view(-1)  # (batch_size * sequence_length)\n",
    "\n",
    "        # create the weighted loss function\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights, ignore_index=-100)\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ],
   "id": "5f8abacc6a81d5e8",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Method to log the loss\n",
    "- Just so I can see more often the progress of the training."
   ],
   "id": "3a5493c7d4ad35fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T22:34:46.333329Z",
     "start_time": "2024-10-21T22:34:46.329286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomLogCallback(TrainerCallback):\n",
    "    def __init__(self, log_interval):\n",
    "        self.log_interval = log_interval\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if state.global_step % self.log_interval == 0 and 'loss' in logs:\n",
    "            print(f\"Step {state.global_step}: Loss: {logs['loss']}\")"
   ],
   "id": "b8ee3d868ae57329",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initializing the model",
   "id": "9890c8860294a424"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T22:34:49.762216Z",
     "start_time": "2024-10-21T22:34:48.246064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we load the model\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_map))\n",
    "model.resize_token_embeddings(len(tokenizer)) # this is done because of the special tokens we added - we need to resize\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-for-product-extraction\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\", # so you don't save all the checkpoints\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "# method to compute metrics\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [reverse_label_map[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [reverse_label_map[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ],
   "id": "5be267c2d23ecca2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5051 949\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T22:39:53.489834200Z",
     "start_time": "2024-10-21T22:34:53.526382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[CustomLogCallback(log_interval=50)] # logs the loss every log_interval steps\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(trainer.evaluate())"
   ],
   "id": "4cd0b199a3da67bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='263' max='632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [263/632 04:48 < 06:48, 0.90 it/s, Epoch 0.83/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
